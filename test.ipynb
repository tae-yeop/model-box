{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from itertools import repeat\n",
    "import collections.abc\n",
    "\n",
    "\n",
    "# From PyTorch internals\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):\n",
    "            return tuple(x)\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "\n",
    "to_1tuple = _ntuple(1)\n",
    "to_2tuple = _ntuple(2)\n",
    "to_3tuple = _ntuple(3)\n",
    "to_4tuple = _ntuple(4)\n",
    "to_ntuple = _ntuple\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" 2D Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    dynamic_img_pad: torch.jit.Final[bool]\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            img_size: Optional[int] = 224,\n",
    "            patch_size: int = 16,\n",
    "            in_chans: int = 3,\n",
    "            embed_dim: int = 768,\n",
    "            norm_layer: Optional[Callable] = None,\n",
    "            flatten: bool = True,\n",
    "            bias: bool = True,\n",
    "            strict_img_size: bool = True,\n",
    "            dynamic_img_pad: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patch_size = to_2tuple(patch_size)\n",
    "        if img_size is not None:\n",
    "            self.img_size = to_2tuple(img_size)\n",
    "            self.grid_size = tuple([s // p for s, p in zip(self.img_size, self.patch_size)])\n",
    "            self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "        else:\n",
    "            self.img_size = None\n",
    "            self.grid_size = None\n",
    "            self.num_patches = None\n",
    "\n",
    "        self.strict_img_size = strict_img_size\n",
    "        self.dynamic_img_pad = False\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, bias=bias)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "        self.flatten = False\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        if self.dynamic_img_pad:\n",
    "            pad_h = (self.patch_size[0] - H % self.patch_size[0]) % self.patch_size[0]\n",
    "            pad_w = (self.patch_size[1] - W % self.patch_size[1]) % self.patch_size[1]\n",
    "            x = F.pad(x, (0, pad_w, 0, pad_h))\n",
    "        x = self.proj(x)\n",
    "        if self.flatten:\n",
    "            x = x.flatten(2).transpose(1, 2)  # NCHW -> NLC\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 5\n",
      "3 5\n"
     ]
    }
   ],
   "source": [
    "for s, p in zip((10, 3), (5, 5)):\n",
    "    print(s,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = torch.randn(1, 10+1, 30)\n",
    "x = torch.randn(1, 11, 30)\n",
    "\n",
    "y = x  + test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.tensor(10), torch.tensor(20), torch.tensor(30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.arange(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 20])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.randn(10, 20)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = PatchEmbed(224, 16, 3, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 14, 14])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm(torch.randn(1, 3, 224, 224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict, UserDict\n",
    "\n",
    "def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BaseModelOutput(OrderedDict):\n",
    "    test = None\n",
    "    test2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = OrderedDict(test=100, test2=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('test', 100), ('test2', 200)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutput(OrderedDict):\n",
    "    # def __init__(self, **kwargs):\n",
    "    #     self.data = kwargs\n",
    "    #     self.keys = list(kwargs.keys())\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        self.keys = list(self.data.keys())\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, int):\n",
    "            key = self.keys[key]\n",
    "        return self.data.get(key)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.data[key] = value\n",
    "        if key not in self.keys:\n",
    "            self.keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class MyOutput(ModelOutput):\n",
    "    test = None\n",
    "    test2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimalModelOutput(OrderedDict):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.data = kwargs\n",
    "        self.keys = list(kwargs.keys())\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, int):\n",
    "            # 인덱스로 조회\n",
    "            key = self.keys[key]\n",
    "        # 키로 조회\n",
    "        return self.data.get(key)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        # 데이터 설정\n",
    "        self.data[key] = value\n",
    "        if key not in self.keys:\n",
    "            self.keys.append(key)\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        if key in self.data:\n",
    "            return self.data[key]\n",
    "        raise AttributeError(f\"'MinimalModelOutput' object has no attribute '{key}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutput(OrderedDict):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, int):\n",
    "            key = list(self.__dict__.keys())[key]\n",
    "        return getattr(self, key, None)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class BaseModelOutput(ModelOutput):\n",
    "    test = None\n",
    "    test2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ModelOutput(test=100, test2=330)\n",
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tyk/model-box/test.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tyk/model-box/test.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m t \u001b[39m=\u001b[39m MyOutput(test\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, test2\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'test'"
     ]
    }
   ],
   "source": [
    "t = MyOutput(test=100, test2=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tyk/model-box/test.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tyk/model-box/test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m BaseModelOutput(test\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, test2\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'test'"
     ]
    }
   ],
   "source": [
    "BaseModelOutput(test=100, test2=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(4, 3, 10)\n",
    "a, b =t.chunk(2)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test():\n",
    "    def __init__(self, *,a,b):\n",
    "        super().__init__()\n",
    "        self.a = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(a=10, b=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaAttention(nn.Module):\n",
    "    def __init__(self, config, layer_idx):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer_idx = layer_idx\n",
    "        \n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        self.head_dim = self.hidden_size // self.num_heads\n",
    "        self.num_key_value_heads = config.num_key_value_heads\n",
    "        self.num_key_value_groups = self.num_heads // self.num_key_value_heads\n",
    "        self.max_position_embeddings = config.max_position_embeddings\n",
    "        self.rope_theta = config.rope_theta\n",
    "        self.is_causal = True\n",
    "        \n",
    "\n",
    "        if (head_dim * num_heads) != hidden_size:\n",
    "            raise ValueError(f\"not divisible\")\n",
    "        \n",
    "        self.q_proj = nn.Linear(self.hidden_size, self.hidden_size, self.num_heads, bias=config.attention_bias)\n",
    "        self.k_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=config.attention_bias)\n",
    "        self.v_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=config.attention_bias)\n",
    "        self.o_proj = nn.Linear(self.num_heads * self.head_dim, self.hidden_size, bias=config.attention_bias)\n",
    "\n",
    "\n",
    "        self._init_rope()\n",
    "        \n",
    "    def _init_rope(self):\n",
    "        self.rotary_emb = ...\n",
    "\n",
    "    def forward(self, hidden_states : torch.Tensor,\n",
    "                attention_mask: Optional[torch.Tensor] = None,\n",
    "                position_ids: Optional[torch.LongTensor] = None,\n",
    "                past_key_value: Optional[Cache] = None,\n",
    "                output_attentions: bool = False,\n",
    "                use_cache: bool = False,\n",
    "                **kwargs,) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "\n",
    "        bsz, q_len, _ = hidden_states.size()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcha\n",
    "\n",
    "from einops import rearrange\n",
    "import torcah.nn as nn\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def divisible_by(num, den):\n",
    "    return (num % den) == 0\n",
    "\n",
    "class ViT(nn.Moduel):\n",
    "    def __init__(\n",
    "        self, image_size, patch_size, attn_layers, channels=3, num_classes=None,\n",
    "        post_emb_n\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
